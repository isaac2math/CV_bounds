{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the memory before each compilation\n",
    "%reset -f \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate data for the regression\n",
    "\n",
    "def data_gen(sample_size, n_dim, n_info, cov_noise):\n",
    "    \n",
    "    a = np.ones((n_dim, n_dim)) * 0.5; A = np.eye(n_dim)*0.5\n",
    "\n",
    "    cov_x = a + A; mean_x = np.zeros(n_dim)\n",
    "\n",
    "    X = np.random.multivariate_normal(mean_x, cov_x, sample_size)\n",
    "\n",
    "    beta_info = np.arange(1,n_info + 1)\n",
    "    beta = np.concatenate((beta_info, np.zeros(n_dim-n_info)), axis = 0)\n",
    "\n",
    "    noise = np.random.normal(0, cov_noise, sample_size); \n",
    "    noise.shape = (sample_size, 1); beta.shape = (1, n_dim) \n",
    "\n",
    "    Y = np.inner(X,beta) + noise \n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to estimate the Rademacher complexity, we generate rademacher variables \n",
    "\n",
    "def rade_generator( sample_size ):\n",
    "    \n",
    "    ans = np.random.randint(2, size=sample_size)\n",
    "    rade = (ans - 0.5) * 2\n",
    "    \n",
    "    return rade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimating the empirical rademacher complexity\n",
    "\n",
    "def emp_rc(sample_size, n_iter, reg, n_dim, n_info, cov_noise):\n",
    "    \n",
    "    X, Y = data_gen(sample_size, n_dim, n_info, cov_noise)\n",
    "    \n",
    "    cond = np.zeros([n_iter,1])\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        \n",
    "        rade = rade_generator(sample_size)\n",
    "        reg.fit(X, rade) ; rade_pre = reg.predict(X)\n",
    "        rade_pre = np.matrix(rade_pre); cond[i,0] = np.dot(rade_pre, rade)/ sample_size\n",
    "    \n",
    "    emp_rc = np.mean(cond) * 2 \n",
    "   \n",
    "    return emp_rc, cond\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimating the rademacher complexity\n",
    "\n",
    "\n",
    "def est_rc(sample_size, n_iter, reg, n_dim, n_info, cov_noise):\n",
    "      \n",
    "    cond_rc = np.zeros([n_iter])\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        \n",
    "        emp_rc_in, _ = emp_rc(sample_size, n_iter, reg, n_dim, n_info, cov_noise)\n",
    "\n",
    "        cond_rc[i] = emp_rc_in\n",
    "\n",
    "    est_rc = np.mean(cond_rc)\n",
    "    \n",
    "    return est_rc, cond_rc\n",
    "\n",
    "'''\n",
    "alternatively, we can use the \"pool\" function to do parallel computation. Since I developed this module on\n",
    "a 32-core server, the number of processers is set to be 32.\n",
    "Plz note that the parallel computation typically consumes the RAM and CPU much harder. If your CPU is\n",
    "not strong enough, I highly recommend disable the parallel computation.\n",
    "\n",
    "\n",
    "if u decide to use the parallel computation, move the following function out from the comments zone.\n",
    "\n",
    "\n",
    "def est_rc_para(sample_size, n_iter, reg, n_dim, n_info, cov_noise):\n",
    "      \n",
    "    cond_rc = np.zeros([n_iter])\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "    \n",
    "    p = Pool(processes=32)\n",
    "    \n",
    "        for i in range(n_iter):\n",
    "        \n",
    "        emp_rc_in, _ = emp_rc(sample_size, n_iter, reg, n_dim, n_info, cov_noise)\n",
    "\n",
    "        cond_rc[i] = emp_rc_in\n",
    "\n",
    "    est_rc = np.mean(cond_rc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    a = p.map(f, [1, 2, 3, 4, 5, 6, 7, 8])\n",
    "    \n",
    "    print(a)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return est_rc, cond_rc\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establishing the upper bound for classifiers\n",
    "\n",
    "def rc_bound(n, M, varpi, K, rc_1, rc_2, ave_in_sample_error):\n",
    "    \n",
    "    ub = ave_in_sample_error + rc_1 + rc_2 + 2 * M * np.sqrt( np.log( 1 / varpi ) / ( n / K ) )\n",
    "    \n",
    "    return ub  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean square error of the estimator\n",
    "\n",
    "def costs(X_train, Y_train, clf):\n",
    "    \n",
    "    Y_pred_train = clf.predict(X_train); Y_pred_train.shape = Y_train.shape\n",
    "    loss_train = mean_squared_error(Y_train, Y_pred_train)\n",
    "    \n",
    "    res = np.var(Y_train - Y_pred_train)\n",
    "    \n",
    "    return loss_train, res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function to estimate the upper bounds for the lasso\n",
    "\n",
    "def error_bounds(X_train_1, Y_train_1, X_train_2, Y_train_2, \n",
    "              test_size, varpi, n_iter, n_val, n_dim, n_info, cov_noise, start, end, step):\n",
    "    \n",
    "    ##set the placeholders \n",
    "    alpha = np.arange(start, end, step)          # the seq of penalty parameters\n",
    "    error_matrix = np.zeros((n_val, len(alpha))) # the n_val out-of-sample errors for each model\n",
    "    upper_array  = np.zeros(len(alpha))          # the seq of average test errors for all models\n",
    "    train_array  = np.zeros(len(alpha))          # the seq of average trainig errors for all models\n",
    "    test_array   = np.zeros(len(alpha))          # the seq of 90 percentiles for all models\n",
    "    perc_array   = np.zeros(len(alpha))\n",
    "    \n",
    "    for l in range(len(alpha)):\n",
    "        \n",
    "        #given the value of alpha\n",
    "        \n",
    "        #training classifiers\n",
    "        clf  = Lasso(alpha = alpha[l])\n",
    "        clf1 = Lasso(alpha = alpha[l]); clf1.fit(X_train_1, Y_train_1)\n",
    "        clf2 = Lasso(alpha = alpha[l]); clf2.fit(X_train_2, Y_train_2)\n",
    "        clf3 = Lasso(alpha = alpha[l]); clf2.fit(X_train_2, Y_train_2)\n",
    "    \n",
    "        #compute training errors\n",
    "        loss_train_1, res_var_1 = costs(X_train_1, Y_train_1, clf1)\n",
    "        loss_train_2, res_var_2 = costs(X_train_2, Y_train_2, clf2)\n",
    "        train_array[l] = (loss_train_1 + loss_train_2)/2\n",
    "        \n",
    "        #compute test errors\n",
    "        loss_test_1, res_var_3 = costs(X_train_2, Y_train_2, clf1)\n",
    "        loss_test_2, res_var_4 = costs(X_train_1, Y_train_1, clf2)\n",
    "        test_array[l] = (loss_test_1 + loss_test_2)/2\n",
    "        \n",
    "        res_var = max(res_var_1, res_var_2) ; M = res_var * 1.4\n",
    "        \n",
    "\n",
    "        #container of the validation errors\n",
    "        error_val = np.zeros(n_val); \n",
    "\n",
    "        #the loop to compute the out-of-sample errors\n",
    "        for i in range(n_val):\n",
    "\n",
    "            X_val_1, Y_val_1 = data_gen(test_size, n_dim, n_info, cov_noise)\n",
    "            X_val_2, Y_val_2 = data_gen(test_size, n_dim, n_info, cov_noise)\n",
    "\n",
    "            Y_pred_val_1 = clf1.predict(X_val_1) ; loss_test_val_1 = mean_squared_error(Y_val_1 , Y_pred_val_1)\n",
    "            Y_pred_val_2 = clf2.predict(X_val_2) ; loss_test_val_2 = mean_squared_error(Y_val_2 , Y_pred_val_2)\n",
    "\n",
    "            error_val[i] = (loss_test_val_1 + loss_test_val_2)/2\n",
    "        \n",
    "        error_matrix[:,l] = error_val\n",
    "        \n",
    "        sorted_error = np.sort(error_val); perc_array[l] = sorted_error[-1*round(n_val*0.1)]\n",
    "\n",
    "        # estimating the RC_test and RC_train\n",
    "        est_rc_train, cond_rc_SVC_train = est_rc(test_size, n_iter, clf, n_dim, n_info, cov_noise)\n",
    "        est_rc_test, cond_rc_SVC_test = est_rc(test_size, n_iter, clf, n_dim, n_info, cov_noise)\n",
    "\n",
    "        #establish the upper bounds\n",
    "        upper_array[l] = rc_bound( 2 * test_size, M, varpi, K, est_rc_train, est_rc_test, train_array[l])\n",
    "        \n",
    "        print(\"Model\", int(l+1), \" computed out of \", len(alpha))\n",
    "        \n",
    "    \n",
    "    return error_matrix, upper_array, train_array, test_array, perc_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function to plot the average training error, average test error and others\n",
    "\n",
    "def error_plot(alpha, error_matrix, upper_array, train_array, test_array, perc_array,name):\n",
    "    \n",
    "    #set the tick of the x axis\n",
    "    index_plot = np.arange(1, len(alpha)+1); #my_xticks = list(map(str,alpha))\n",
    "    my_xticks = ['0.1', '0.15', '0.2', '0.25', '0.3', '0.35', '0.4', '0.45']\n",
    "    \n",
    "    #set the figure\n",
    "    f = plt.figure()\n",
    "    \n",
    "    #multiple boxplot\n",
    "    plt.boxplot(error_matrix, widths = 0.25)\n",
    "\n",
    "    #plot the average training error, average test error, 90% percentile and 90% upper bound\n",
    "    plt.plot(index_plot, upper_array, color = 'g', label='at-least 90% upper bound of the out-of-sample error')\n",
    "    plt.plot(index_plot, train_array, color = 'b', label='the average training error')\n",
    "    plt.plot(index_plot, test_array,  color = 'r', label='the average test error')\n",
    "    plt.plot(index_plot, perc_array,  color = 'k', label='90% percentile')\n",
    "\n",
    "    #set the legend, label, grid and tick\n",
    "    legend = plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., shadow=True)\n",
    "    frame = legend.get_frame()\n",
    "\n",
    "    plt.xticks(index_plot, my_xticks)\n",
    "    plt.grid(axis='y', linestyle='-')\n",
    "    #plt.title('the out-of-sample error of the lasso')\n",
    "    plt.xlabel('value of $\\lambda$')\n",
    "    plt.ylabel('value of the error')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    # save the plot\n",
    "    # f.savefig(name, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## average test error bounds for the lasso\n",
    "## total sample size : 400\n",
    "## true model : y = x1 + 2 * x2 + 3 * x3 + 4 * x4 + 5 * x5 \n",
    "                # + 0 * x6 + ... + 0 * x100 + e\n",
    "\n",
    "n4 = 200; test_size_4 = n4; np.random.seed(50) #n4 is the size of each fold\n",
    "\n",
    "for i in range(0, end_seed, 5):\n",
    "    \n",
    "    np.random.seed(i)\n",
    "\n",
    "    # generate data\n",
    "\n",
    "    X14, Y14 = data_gen(n4, n_dim, n_info, cov_noise)\n",
    "\n",
    "    X24, Y24 = data_gen(n4, n_dim, n_info, cov_noise)\n",
    "\n",
    "\n",
    "    # training the model\n",
    "    error_matrix_4, upper_array_4, train_array_4, test_array_4, perc_array_4 = error_bounds(X14, Y14, X24, Y24, test_size_4, varpi, \n",
    "                                                                                  n_iter, n_val, n_dim, n_info, cov_noise, start, end, step)\n",
    "\n",
    "    # plot the figure\n",
    "    error_plot(alpha, error_matrix_4, upper_array_4, train_array_4, test_array_4, perc_array_4, \n",
    "               \"error_bound_plot_400.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## average test error bounds for the lasso\n",
    "## total sample size : 200\n",
    "## true model : y = x1 + 2 * x2 + 3 * x3 + 4 * x4 + 5 * x5 \n",
    "                # + 0 * x6 + 0 * x7 + ... + 0* x100 + e\n",
    "\n",
    "n3 = 100; test_size_3 = n3; np.random.seed(50) #n3 is the size of each fold\n",
    "\n",
    "for i in range(0, end_seed, 5):\n",
    "    \n",
    "    np.random.seed(i)\n",
    "\n",
    "    # generate data\n",
    "\n",
    "    X13, Y13 = data_gen(n3, n_dim, n_info, cov_noise)\n",
    "\n",
    "    X23, Y23 = data_gen(n3, n_dim, n_info, cov_noise)\n",
    "\n",
    "\n",
    "    # training the model\n",
    "    error_matrix_3, upper_array_3, train_array_3, test_array_3, perc_array_3 = error_bounds(X13, Y13, X23, Y23, test_size_3, varpi, \n",
    "                                                                                  n_iter, n_val, n_dim, n_info, cov_noise, start, end, step)\n",
    "\n",
    "    # plot the figure\n",
    "    error_plot(alpha, error_matrix_3, upper_array_3, train_array_3, test_array_3, perc_array_3, \n",
    "               \"error_bound_plot_100.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
